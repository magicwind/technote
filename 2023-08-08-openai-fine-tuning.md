# 微调
学习如何为您的应用定制模型。

## 简介
微调使您通过提供以下功能从API可用的模型中获得更多优势：
1. 比提示设计更高质量的结果
2. 能够在提示中容纳的示例之外进行训练
3. 由于提示较短而节省令牌
4. 请求延迟更低

GPT-3已在开放互联网上的大量文本上进行了预训练。当给出一个只有几个例子的提示时，它通常可以直观地了解您试图执行的任务，并生成一个合理的完成。这通常被称为“少数样本学习”。

通过在提示中容纳的许多更多示例上训练，微调改善了少数样本学习，让您在许多任务上取得更好的效果。一旦模型被微调，您将不再需要在提示中提供示例。这节省了成本，并实现了更低延迟的请求。

从高层次来看，微调涉及以下步骤：

1. 准备和上传训练数据
2. 训练一个新的微调模型
3. 使用您的微调模型

## 哪些模型可以进行微调？

微调目前仅适用于以下基本模型：davinci、curie、babbage和ada。这些是不进行任何指令后训练的原始模型（例如text-davinci-003）。您还可以继续微调一个已经微调过模型，以添加额外的数据，而无需从头开始。

## 安装
我们推荐使用OpenAI的命令行界面（CLI）。要安装它，请运行

`pip install --upgrade openai`

（以下指令适用于0.9.4及更高版本。此外，OpenAI CLI需要python 3。）

通过在您的shell初始化脚本（例如.bashrc、zshrc等）中添加以下行或在微调命令之前在命令行中运行它，设置您的OPENAI_API_KEY环境变量：

```bash
export OPENAI_API_KEY="<OPENAI_API_KEY>"
```

## 准备训练数据

训练数据是您教GPT-3您想让它说什么的方式。

您的数据必须是JSONL文档，其中每一行都是一个提示完成对，对应一个训练示例。您可以使用我们的CLI数据准备工具轻松将您的数据转换为此文件格式。
```jsonl
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
...
```
为微调设计您的提示和完成与为我们的基本模型（Davinci、Curie、Babbage、Ada）使用设计您的提示不同。特别是，虽然基本模型的提示通常包括多个示例（“少数样本学习”），但对于微调，每个训练示例通常由单个输入示例及其关联输出组成，无需给出详细指令或在同一提示中包括多个示例。

有关如何为各种任务准备训练数据的更详细指导，请参考我们[准备数据集](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset)的最佳实践。

您拥有的训练示例越多越好。我们建议至少有几百个示例。总的来说，我们发现数据集大小每增加一倍都会导致模型质量的线性提高。

