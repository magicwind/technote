<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>魔风的技术小屋</title>
    <description>本博客专注于大数据分析平台相关技术的分享。记录经验与此，供自己温故而知新，也便于分享。</description>
    <link>https://magicwind.top/</link>
    <atom:link href="https://magicwind.top/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Mon, 09 Feb 2026 23:29:42 -0600</pubDate>
    <lastBuildDate>Mon, 09 Feb 2026 23:29:42 -0600</lastBuildDate>
    <generator>Jekyll v4.3.2</generator>
    
      <item>
        <title>[置顶]基于Amazon Bedrock的text2sql解决方案介绍</title>
        <description>&lt;h2 id=&quot;什么是text2sql技术&quot;&gt;什么是text2sql技术?&lt;/h2&gt;

&lt;p&gt;text2sql是一种自然语言理解技术,可以将用户用自然语言提出的问题自动转换成数据库查询语句。用户只需要用自然语言描述问题,text2sql系统就可以生成对应的SQL查询语句,从数据库中获取结果。这极大地简化了数据库查询的过程,用户无需了解SQL语法,就可以通过语音或文本进行数据分析和查询。&lt;/p&gt;

&lt;h2 id=&quot;什么是amazon-bedrock&quot;&gt;什么是Amazon Bedrock&lt;/h2&gt;

&lt;p&gt;Amazon Bedrock是一个无服务器的机器学习服务,可以帮助开发者快速构建自然语言理解应用。它内置了预训练好的语言模型,开发者可以通过简单的配置就获得强大的NLP能力,如命名实体识别、情感分析、文本分类等。Bedrock还提供了对话管理功能,可以帮助开发任务型对话机器人。&lt;/p&gt;

&lt;h2 id=&quot;用户使用场景&quot;&gt;用户使用场景&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;面向运营人员的销售数据分析, 根据数据库里的销售明细数据,按照时间、产品、地区、客户等维度分析销售额、利润等指标。例如,运营人员可以通过语音提问“上个月北京地区笔记本电脑的销售额是多少?”,text2sql系统即可自动生成SQL语句,从数据库提取上个月北京地区笔记本电脑的销售总额。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;面向销售人员的绩效数据查询, 根据SFE数据库里的销售数据,分析销售个人或者团队的绩效达成情况。例如,销售人员可以通过语音提问“我这个月的销售业绩完成率是多少?”,text2sql系统可以自动统计出该销售人员本月的销售目标和实际完成数,计算出销售业绩完成率。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;解决方案特点&quot;&gt;解决方案特点&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;利用最先进的闭源和开源LLM来生成SQL,API调用按Token数量进行计费,没有任何运行时开销。这可以确保生成的SQL语句语义正确、符合业务逻辑,而且计费方式灵活。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;利用AWS托管服务来减少运维开销,例如使用Amazon EC2提供可靠的计算资源,使用Amazon RDS来托管关系数据库。开发者无需管理基础设施,可以更专注于应用开发。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;使用IaC工具编写代码来初始化和更新基础架构,实现自动化部署,提高敏捷性。开发者可以使用AWS CloudFormation, AWS CDK等IaC工具,通过代码控制基础架构的部署和更新。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;用户体验&quot;&gt;用户体验&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;提供Web UI供业务用户进行聊天式数据查询。用户无需了解SQL语法,通过聊天界面输入问题,即可获取结果,操作非常简单方便。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;提供后台配置界面供模型调优人员进行配置。模型调优人员可以通过友好的界面管理数据库Schema标注、管理向量Embedding数据等,无需修改代码即可优化对话效果。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;更多技术细节参考&quot;&gt;更多技术细节参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/cn/blogs/china/build-text2sql-industry-data-query-assistant-using-bedrock-and-rag/&quot;&gt;使用 Bedrock 和 RAG 构建 Text2SQL 行业数据查询助手&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/cn/blogs/china/design-and-implementation-of-llm-rag-conversational-robot-and-text2sql/&quot;&gt;浅谈 LLM RAG 对话机器人和 Text2SQL 的设计和实现&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;代码参考&quot;&gt;代码参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/aws-samples/generative-bi-using-rag&quot;&gt;Generative BI with RAG Demo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/aws-solutions-library-samples/guidance-for-natural-language-queries-of-relational-databases-on-aws&quot;&gt;Guidance for Natural Language Queries of Relational Databases on AWS&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 31 Dec 2098 18:00:00 -0600</pubDate>
        <link>https://magicwind.top/genai/2098/12/31/pinned-text2sql-solution/</link>
        <guid isPermaLink="true">https://magicwind.top/genai/2098/12/31/pinned-text2sql-solution/</guid>
        
        
        <category>genai</category>
        
      </item>
    
      <item>
        <title>广告行业新闻系统上线</title>
        <description>&lt;p&gt;今日，专用的广告行业新闻收集系统正式在 technote 博客上线。该系统可以自动化收集、整理和发布每日广告行业的重要新闻和趋势分析。&lt;/p&gt;

&lt;p&gt;主要功能包括：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;自动生成符合 Jekyll 格式的文章&lt;/li&gt;
  &lt;li&gt;支持标签分类&lt;/li&gt;
  &lt;li&gt;集成 Git 版本控制&lt;/li&gt;
  &lt;li&gt;一键推送到 GitHub Pages&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;未来我们将持续关注广告技术、营销自动化、隐私保护等领域的最新动态。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;em&gt;来源: 每日广告行业观察&lt;/em&gt;&lt;br /&gt;
&lt;em&gt;发布时间: 2026-02-10&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 09 Feb 2026 15:28:17 -0600</pubDate>
        <link>https://magicwind.top/ad-news,%E7%B3%BB%E7%BB%9F%E5%85%AC%E5%91%8A/2026/02/09/%E5%B9%BF%E5%91%8A%E8%A1%8C%E4%B8%9A%E6%96%B0%E9%97%BB%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%BA%BF/</link>
        <guid isPermaLink="true">https://magicwind.top/ad-news,%E7%B3%BB%E7%BB%9F%E5%85%AC%E5%91%8A/2026/02/09/%E5%B9%BF%E5%91%8A%E8%A1%8C%E4%B8%9A%E6%96%B0%E9%97%BB%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%BA%BF/</guid>
        
        
        <category>ad-news,系统公告</category>
        
      </item>
    
      <item>
        <title>面向隐私至上环境下的营销人员数据洁净室和数据协作指南</title>
        <description>&lt;h1 id=&quot;面向隐私至上环境下的营销人员数据洁净室和数据协作指南&quot;&gt;面向隐私至上环境下的营销人员数据洁净室和数据协作指南&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.credera.com/en-us/insights/data-clean-room-series-part-1-a-marketers-guide-to-data-clean-rooms-and-data-collaboration-in-a-privacy-first-landscape&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;在数字广告的未来,有一点是明确的:隐私必须摆在首位。然而,一波影响广告技术行业的监管和技术变革,使隐私优先的营销策略在执行层面蒙上了阴影。在营销人员正在考虑的所有解决方案中,数据洁净室可能是最有前景的,能够为业务带来长期价值;但它们也很复杂,需要大量投资来建立和使用,这对于许多营销人员来说是一个很高的进入壁垒。&lt;/p&gt;

&lt;p&gt;在这个关于数据洁净室系列文章的第一篇文章中,我们将探讨:如何定义数据洁净室及其工作原理、营销人员如何通过数据协作实现业务价值的实例、数据洁净室提供商的格局,以及营销人员制定数据协作策略时需要考虑的因素。&lt;/p&gt;

&lt;h2 id=&quot;为什么我们要谈论数据洁净室&quot;&gt;为什么我们要谈论数据洁净室?&lt;/h2&gt;

&lt;p&gt;根据Gartner的预测,到2024年,全球75%以上的人口的个人信息将受到现代隐私法规的保护。&lt;/p&gt;

&lt;p&gt;这些法规规范了如何收集、存储和使用客户数据,包括欧洲的通用数据保护条例(GDPR)、已生效或计划于2023年生效的美国州立法,以及全球其他地区的更多法规。对营销人员的影响还被行业内的其他变化加剧,即第三方标识符(Cookies和移动标识符)的废弃,以及广告技术因壁垒式生态系统而日益分散。&lt;/p&gt;

&lt;p&gt;因此,营销人员迫切需要确定符合隐私合规要求的新解决方案,用于活动策划、受众激活、测量和归因,并能带来相同(或更好)的业务成果。&lt;/p&gt;

&lt;p&gt;发展坚实的第一方数据策略,并了解如何利用第二方和第三方数据源,对于任何应对不断演变的隐私格局的解决方案都至关重要。然而,在Credera对200名全球营销总监进行的最新调查中,超过一半(51%)的受访者表示”我们还没有开始”或”还有很多工作要做”,才能将重点重新放在第一方数据收集上。&lt;/p&gt;

&lt;p&gt;数据洁净室由此而来。&lt;/p&gt;

&lt;p&gt;营销人员正在将数据洁净室解决方案作为2023年的重点,以最大限度地利用第一方数据,并在保护消费者隐私的同时,实现现有和新的营销用例的大规模应用。这些安全环境是数据协作的基础,提供了利用新数据集、释放客户数据的总体价值,并提供有影响力的个性化客户体验的能力。&lt;/p&gt;

&lt;h2 id=&quot;数据洁净室解释&quot;&gt;数据洁净室解释&lt;/h2&gt;

&lt;h3 id=&quot;什么是数据洁净室它是如何工作的&quot;&gt;什么是数据洁净室,它是如何工作的?&lt;/h3&gt;

&lt;p&gt;数据洁净室是一个安全的基于云的环境,旨在让两个或多个方面加入数据集进行分析,而不会危及消费者或数据所有者的隐私。敏感数据不会直接在合作伙伴之间交换,分析结果会以汇总级别返回,因此无法识别单个消费者。&lt;/p&gt;

&lt;p&gt;随着数据洁净室在当今环境中的发展,以前存在的许多技术和法律障碍阻碍数据共享已被消除,从而为品牌之间建立新的更强大的合作伙伴关系带来机会,这些合作伙伴关系建立在更高的透明度和信任之上。&lt;/p&gt;

&lt;p&gt;不同数据洁净室提供商之间的功能和技术能力会有所不同,但是这些环境为实现隐私合规的数据协作所采用的机制可以概括为以下高层级内容:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;原始数据受到安全加密保护&lt;/strong&gt;,因此无法查看或离开数据洁净室环境的用户级数据或个人身份信息(PII)。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;数据摄取的方法多种多样&lt;/strong&gt;,从完全分布式(无数据移动)到需要第三方基础设施(如客户数据平台[CDP])。
使用原生方法或利用第三方身份提供商,&lt;strong&gt;数据在用户级别连接或匹配&lt;/strong&gt;。
&lt;strong&gt;采用各种隐私保护措施&lt;/strong&gt;,以防在任何分析阶段泄露或暴露敏感数据;技术因供应商而异,包括差分隐私、噪声注入、加密等。
&lt;strong&gt;每个协作者都可以定义适当的数据访问权限和分析规则&lt;/strong&gt;,因此数据所有者可以完全控制谁可以访问他们的数据以及如何使用;在大多数情况下,这些权限可以随时撤销。
最终结果是可用于洞察、激活和/或测量的&lt;strong&gt;汇总营销数据&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://images.ctfassets.net/76f8cs5bg9si/4DyD69BYOcAZhZQRSYJ1sf/d06f68e88aa5bfcfe9e05eb9ad20a958/Data_Clean_Rooms__1_.png&quot; width=&quot;500&quot; alt=&quot;数据洁净室:功能概述&quot; /&gt;
数据洁净室:功能概述&lt;/p&gt;

&lt;p&gt;通过数据洁净室实现数据协作,可以让品牌、发布商和数据提供商访问新的数据集,帮助营销活动应对不断变化的监管和广告技术环境。获取以前无法访问的数据,也为企业开辟了探索全新用例的大门,从而为客户创造更大价值。&lt;/p&gt;

&lt;h3 id=&quot;数据洁净室如何创造价值&quot;&gt;数据洁净室如何创造价值?&lt;/h3&gt;

&lt;p&gt;例如,发布商可以通过数据洁净室提供他们宝贵的第一方数据,协助广告商进行更智能的活动策划和更丰富的受众洞察,从而创造新的收入来源,并继续从广告商获得对平台的投资——同时无需交出对这些数据的所有权或使用权。&lt;/p&gt;

&lt;p&gt;消费品行业利用零售媒体网络也是一个双赢的好例子:缺乏第一手数据的消费品公司可以借助零售商的数据洁净室(如沃尔马特连接、Instacart、最近的亚伯森超市),安全获取交易数据,并对自身广告活动进行闭环测量。&lt;/p&gt;

&lt;p&gt;虽然上述场景直接与广告相关,但数据洁净室所支持的数据协作用例已经扩展到付费媒体之外的定位、激活和测量之外。汽车、旅游、娱乐等行业的公司都在利用更多受众信号来完善对客户旅程的理解,创造更个性化的客户体验。&lt;/p&gt;

&lt;h2 id=&quot;数据洁净室格局&quot;&gt;数据洁净室格局&lt;/h2&gt;
&lt;p&gt;数据洁净室解决方案持续增多,新来者定期进入这一市场。与此同时,已经站稳脚跟的参与者也在不断改进他们的产品和服务。观察市场上的各种选择,目前大多数数据洁净室解决方案可分为两大类:封闭生态系统和中立洁净室。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://images.ctfassets.net/76f8cs5bg9si/3evWtgN420MOEMJbxFCOWc/651a26cddc5b9c4531ae9db5b17ef7ad/Data_Clean_Rooms2__1_.png&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;p&gt;根据他们的具体功能、架构和特征,上述每一类别的提供商都可以进一步细分。我们将在未来的博客文章中更详细地探讨这些群体及其关键参与者。&lt;/p&gt;

&lt;h2 id=&quot;营销人员为数据洁净室中的数据协作做准备的两种方式&quot;&gt;营销人员为数据洁净室中的数据协作做准备的两种方式&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;召集合适的利益相关方
对营销人员来说,数据洁净室的复杂性在于确定并协调来自整个企业的内部资源。建立和执行数据协作策略需要几个利益相关者团队参与,就共享第一方数据达成隐私和法规合规协议。根据具体组织情况,这可能需要营销、法务、数据科学和营销分析、IT、产品和销售等团队的代表参与。如果你是数据洗净室的所有者,你还需要解决将其产品化和构建平台能力等方面的问题。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;为数据协作做好准备
无论组织是构建自己的数据洁净室解决方案,还是加入由另一个实体托管的新协作,营销人员都需要准备好他们的第一方数据以便进行联合分析。虽然每个提供商都有自己的一套要求和解决方案,但有一些共同的需求,以确保数据处于可被数据洁净室使用的位置和格式:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;定义和编目数据源:首先,团队需要选择并定义包含他们希望用于协作的数据的数据源。&lt;/li&gt;
      &lt;li&gt;集中和规范化数据:客户和活动数据可能来自多个来源,因此需要通过一个中央位置和流程(通常由数据洁净室提供商指定)使其可访问,并规范化格式以便与环境中的其他数据匹配。&lt;/li&gt;
      &lt;li&gt;确定匹配键:在加入新的协作之前,参与者需要确定将在数据洁净室内用于连接集体数据的标识符(如电子邮件地址)。&lt;/li&gt;
      &lt;li&gt;理解输出:营销人员应确保协作的输出可用于所需的用例,如在媒体环境中激活受众,并且具有正确的连接器。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;开启数据洁净室之旅&quot;&gt;开启数据洁净室之旅&lt;/h2&gt;
&lt;p&gt;在注重隐私的环境下,数据协作的价值是显而易见的,但营销人员要充分发挥数据洁净室的真正潜力,仍有诸多挑战需要克服。处理内部资源和第一方数据只是开始。即使对于最精通数据的组织,在不确定性和持续隐私变革的背景下,理解数据洁净室的细微差异并构建适当的解决方案也是一项艰巨的任务 —— 特别是在面临 Cookie 弃用的压力时更是如此。&lt;/p&gt;

&lt;p&gt;在 Credera,我们帮助客户突破挑战,最大限度地发挥他们第一方数据的价值,建立数据协作策略,并实施数据洁净室解决方案,加速为客户和业务创造即时价值。&lt;/p&gt;

&lt;p&gt;请继续关注我们关于数据洁净室的四部分系列文章:营销人员如何使用数据洁净室进行隐私优先广告投放、通过数据洁净室实现数据货币化的机会,以及为营销人员提供数据洁净室格局中关键参与者的指导,并帮助识别适合其业务的正确解决方案。&lt;/p&gt;
</description>
        <pubDate>Mon, 15 Jul 2024 00:00:00 -0500</pubDate>
        <link>https://magicwind.top/data/clean/room/2024/07/15/clean-room-part1/</link>
        <guid isPermaLink="true">https://magicwind.top/data/clean/room/2024/07/15/clean-room-part1/</guid>
        
        
        <category>data</category>
        
        <category>clean</category>
        
        <category>room</category>
        
      </item>
    
      <item>
        <title>在斐讯N1盒子上安装CasaOS</title>
        <description>&lt;h1 id=&quot;casaos介绍&quot;&gt;CasaOS介绍&lt;/h1&gt;
&lt;p&gt;CasaOS,这是一款由IceWhale公司推出的全新操作系统(严格来说, 是一个可以在Armbian等操作系统上安装的NAS应用)。&lt;/p&gt;

&lt;p&gt;IceWhale是一家位于中国的高科技公司,专注于开发创新的软硬件解决方案。他们的愿景是打造一个开放、高效、安全的计算环境,满足个人和企业用户的不同需求。CasaOS正是IceWhale为实现这一目标而推出的开源操作系统。&lt;/p&gt;

&lt;p&gt;CasaOS的核心理念是提供一个轻量级、模块化的操作系统,用户可以根据自己的需求,选择安装所需的组件。该系统基于Linux内核构建,采用了全新的图形界面设计,拥有现代化的外观和流畅的用户体验。同时,CasaOS还提供了强大的安全防护措施,确保用户的数据和隐私得到全面保护。&lt;/p&gt;

&lt;p&gt;该系统的另一大亮点是对ARM架构的优化支持。随着物联网、边缘计算等新兴技术的发展,ARM处理器正在越来越多的设备中应用。CasaOS正是针对这一趋势做了大量优化工作,确保在ARM平台上表现出色。&lt;/p&gt;

&lt;h1 id=&quot;准备工作&quot;&gt;准备工作&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;以N1盒子为例，最新的固件去&lt;a href=&quot;https://github.com/ophub/amlogic-s9xxx-armbian/releases&quot;&gt;GitHub&lt;/a&gt;下载，大佬一直在更新。
在Release下面下载这个文件（版本号和后缀时间可能不同）：
版本有Jammy(Ubuntu系统)和bookworm(Debian系统)2种, 都是LTS长时间支持的版本. 内核我选6.1的, 因为bookworm版本比Jammy版本体积要小(前者700MB, 后者900MB), 选了下载前者.&lt;/p&gt;

    &lt;p&gt;文件名: Armbian_24.5.0_amlogic_s905d_bookworm_6.1.82_server_2024.03.16.img.gz&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;下载U盘写入工具，可以使用balenaEtcher或rufus, 将下载的Armbian镜像写入U盘&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;将U盘插入靠近HDMI口的USB接口里，插电，自动进入U盘系统。&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;: 此步骤需要之前刷过机，可以从USB启动。如果不确定，那就先试试，如果启动不了，参照B站的教程刷吧。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在路由器后台看到armbian设备，记住IP地址，用SSH工具登录。下面以Windows11的CMD命令提示符为例。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;armbian安装&quot;&gt;Armbian安装&lt;/h1&gt;
&lt;p&gt;SSH进入Armbian系统: ssh root@ip_addr.&lt;/p&gt;

&lt;p&gt;需要修改root密码.&lt;/p&gt;

&lt;p&gt;命令行选zsh&lt;/p&gt;

&lt;p&gt;然后创建一个新用户,并设置密码.&lt;/p&gt;

&lt;p&gt;最后设置时区和语言.&lt;/p&gt;

&lt;p&gt;接下来执行armbian-install命令开始安装.&lt;/p&gt;

&lt;p&gt;设备ID选择101 (N1),文件系统选择ext4, 然后等待安装, 安装结束后执行poweroff命令,关机并拔下电源和USB盘,再重新上电.&lt;/p&gt;

&lt;p&gt;到这里,armbian操作系统就装好了,系统已经安装到N1内置的存储上了, 启动结束后可以使用SSH重新登录,这里建议使用新建的用户名登录.&lt;/p&gt;

&lt;h1 id=&quot;casaos安装&quot;&gt;CasaOS安装&lt;/h1&gt;
&lt;p&gt;现在开始安装CasaOS, 安装只需要执行一条命令就可以了: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;curl -fsSL https://get.casaos.io | sudo bash&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;然后需要输入密码,因为是非root用户安装.&lt;/p&gt;

&lt;p&gt;看到一个告警, 剩余磁盘空间小于5GB, 是否继续安装, 输入1.&lt;/p&gt;

&lt;p&gt;更新package manager比较慢, 有访问国外网站的网速有关系,请耐心等待.&lt;/p&gt;

&lt;p&gt;casaos安装完毕直接可以在浏览器打开armbian的IP地址，不用输入端口号，自动进入casaos界面&lt;/p&gt;

&lt;p&gt;创建用户名和密码就可以登录了。&lt;/p&gt;

&lt;p&gt;用户名自定义，不要用root&lt;/p&gt;

&lt;p&gt;casaos对大佬来说可能作用不是很大，但对我来说是非常好的系统，安装软件和挂载硬盘都简单了许多。&lt;/p&gt;

&lt;p&gt;安装其他软件，例如qbittorrent, 打开App Store, 搜索qbit. 然后点击安装. 安装完成后, 可以看到应用图标出现在桌面上, 然后再点击设置, 在设置窗口里的右上角查看日志, 可以获取admin临时密码.&lt;/p&gt;

&lt;p&gt;桌面点击qbittorrent图标打开web应用, 输入用户名admin和刚刚获取的临时密码登录. 在设置里可以修改语言.&lt;/p&gt;

&lt;p&gt;qbittorrent的安装就先讲到这里, 实际使用还会外挂USB硬盘才行.&lt;/p&gt;

&lt;p&gt;CasaOS对USB支持也相当不错, 把硬盘插入USB后, 就能在桌面看到硬盘, 然后可以在文件应用里查看文件系统了.&lt;/p&gt;

&lt;p&gt;先讲到这里, 有什么问题可以在评论区留言.&lt;/p&gt;

&lt;p&gt;本教程视频可以访问: &lt;a href=&quot;https://www.bilibili.com/video/BV1sm421n73J/?share_source=copy_web&amp;amp;vd_source=0d9d401ed97967bb285e97ad2617e06e&quot;&gt;N1上如何安装CasaOS - 轻量级NAS系统&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 30 Mar 2024 00:00:00 -0500</pubDate>
        <link>https://magicwind.top/casaos/2024/03/30/install-casaos-on-n1/</link>
        <guid isPermaLink="true">https://magicwind.top/casaos/2024/03/30/install-casaos-on-n1/</guid>
        
        
        <category>casaos</category>
        
      </item>
    
      <item>
        <title>基于云的协作是广告技术后Cookie时代的救命稻草 – 但它能持续吗?</title>
        <description>&lt;p&gt;云基础设施供应商正在渗透到数据驱动的广告领域。&lt;/p&gt;

&lt;p&gt;第三方广告技术公司正在成为使用公有云来构建解决方案的服务提供商 – 主要是亚马逊云科技 (AWS)、谷歌云平台 (GCP)、Snowflake 和微软 Azure。&lt;/p&gt;

&lt;p&gt;这一趋势催生了数据Clean Room和Customer Data Platform等技术,对于许多大的广告主而言,在后Cookie时代需要将云服务纳入计划。&lt;/p&gt;

&lt;p&gt;如果你问问云厂商自己,他们可能会称之为Daft Punk革命 – 更好、更快、更强大。但MarTech公司选择在云平台下构建业务的真正原因是用户隐私。&lt;/p&gt;

&lt;p&gt;不过,问题依然存在:这种跨云协作系统能否在现实世界中发挥作用?也就是说,对营销人员是否有用,同时又能通过监管机构和隐私保护拥护者的审查。&lt;/p&gt;

&lt;p&gt;用户隐私法律和平台数据政策侧重于限制可访问数据的业务数量,而不是禁止广告定位或归因等特定行为。这就是为什么苹果的ATT更新破坏了Facebook的广告平台,而亚马逊广告却在后疫情时代电商放缓的时期继续运营。Facebook需要其他企业共享数据,而亚马逊已经将数据集中到一个地方。&lt;/p&gt;

&lt;p&gt;如果新的法规要求数据放在一个地方,那么供应商在那里开展业务就是唯一合乎逻辑的做法。&lt;/p&gt;

&lt;h2 id=&quot;跨云协作实际上是如何实现的&quot;&gt;跨云协作实际上是如何实现的&lt;/h2&gt;

&lt;p&gt;一个挑战是,广告技术和数据供应商对技术有深入的理解,但客户往往没有。&lt;/p&gt;

&lt;p&gt;去年,一位大饮料品牌的营销人员告诉我,她已经开始在The Trade Desk和沃尔玛的Connect DSP上运行多个广告系列（Campaign）,后者是基于The Trade Desk构建的。
她说,通过ID映射,品牌方可以将特定媒体渠道归因于沃尔玛的销售,并对沃尔玛的客户在访问其他商店或发布商时对其进行再营销。&lt;/p&gt;

&lt;p&gt;等等!&lt;/p&gt;

&lt;p&gt;这难道不是沃尔玛Connect DSP希望禁止的行为吗?&lt;/p&gt;

&lt;p&gt;是的,的确如此。&lt;/p&gt;

&lt;p&gt;基于云的用户定向和归因通常无法被审计,也无法增强品牌自身的客户数据。但从营销人员的角度来看,他们仍在使用熟悉的仪表板来采用常见策略。&lt;/p&gt;

&lt;p&gt;例如,沃尔玛Connect DSP这样的围墙花园可能会生成一个人群包,可以在TikTok、Roku或Snapchat上对其进行再营销,然后促进购买转化。数据还可能被放入一个Clean Room,在那里ID可以在不暴露个人信息的情况下用于再营销。&lt;/p&gt;

&lt;p&gt;作为跨云协作如何真实地运作的另一个例子,可以参考LiveRamp和亚马逊营销云(AMC),后者是由亚马逊广告运营的数据Clean Room。&lt;/p&gt;

&lt;p&gt;2月,LiveRamp宣布与亚马逊建立合作伙伴关系,使得LiveRamp的ID解决方案RampID可以”用作将第一方和第三方见解与亚马逊广告在亚马逊营销云中的关联键,以实现测量,并直接在亚马逊DSP内基于RampID激活特定品牌的受众”。&lt;/p&gt;

&lt;p&gt;如果你没有完全理解这些行业黑话,也不足为奇 - 而且如果你是营销人员,这种复杂性对你的日常工作影响相对较小。&lt;/p&gt;

&lt;p&gt;品牌营销人员不需要知道模算数来解释两方如何能够通过计算得出一个和而不暴露公式中的数字。&lt;/p&gt;

&lt;p&gt;对于LiveRamp和AMC来说,情况很复杂。他们不仅仅是像以前的数据上传那样匹配和增强个人资料。&lt;/p&gt;

&lt;p&gt;亚马逊广告中加密的受众与RampID图中的加密实例相匹配。亚马逊DSP不知道它代表广告主中的哪个用户去重新定位 - 它只有一个加密的RampID。LiveRamp也不会得知是谁完成了购买,只知道总的转化数量。同时,广告主也不知道它重新定位了谁,也没有数据被添加到其第一方CRM系统中。&lt;/p&gt;

&lt;p&gt;但用户级别的再营销和购买转化确实发生了。&lt;/p&gt;

&lt;p&gt;广告技术就像一家精致的餐厅,至少目前还能在就餐区保持整洁和优雅,而把脏活累活留在厨房里。&lt;/p&gt;

&lt;h2 id=&quot;潜在缺陷&quot;&gt;潜在缺陷&lt;/h2&gt;

&lt;p&gt;但回到主要问题 - 跨云协作能否奏效?&lt;/p&gt;

&lt;p&gt;好吧,事实是,它确实有效。就在我们谈话时,数十亿营销资金正通过这个系统流动。&lt;/p&gt;

&lt;p&gt;然而,也有一些警示。&lt;/p&gt;

&lt;p&gt;就在上周,由隐私研究员Wolfie Christl和Alan Toner合著的一份报告发现,LiveRamp有一个相当安全的加密和单向数据处理系统,但”在GDPR下,其中一些措施至少是可以质疑的”。&lt;/p&gt;

&lt;p&gt;例如,LiveRamp的客户各有自己的RampID的伪匿名实例。这意味着一个为Hershey’s和Mondelez使用RampID的DSP或身份供应商无法跨客户比对数据。当代理商或广告技术公司代表多个品牌使用谷歌的基于云的数据清洗室Ads Data Hub时,谷歌也设置了类似的屏障。&lt;/p&gt;

&lt;p&gt;然而,Christl和Toner指出,一些RampID客户本身就是数据经纪商、DSP 或 SSP,维护着自己的身份系统。他们将伪匿名的RampID整合到结果中,并将这些结果(有时甚至是特定受众)传递给其他客户。&lt;/p&gt;

&lt;p&gt;LiveRamp的隐私措施旨在禁止广告主、广告技术公司或媒体重新识别个人。该报告确实承认LiveRamp在这方面做得很好。&lt;/p&gt;

&lt;p&gt;但如果法律被解释为禁止跨不同数据库和公司关联个人数据呢?&lt;/p&gt;

&lt;p&gt;没有什么能阻止欧洲数据保护机构追究这种解释。&lt;/p&gt;

&lt;p&gt;根据一些品牌营销人员(和自夸的新闻稿),品牌可以跨越云基础设施服务和数字媒体平台跟踪和归因消费者ID,而每个平台本身据称都是一个独立的围墙花园。&lt;/p&gt;

&lt;p&gt;这意味着协作软件公司应该尽快教育客户有关其隐私框架的工作方式。他们还应该避免过度吹牛。&lt;/p&gt;

&lt;p&gt;因为基于云的广告技术是广告主实现后Cookie时代解决方案的最大的希望。但如果数据协作技术供应商存在漏洞的话,他们将成为下一个需要解决的问题。&lt;/p&gt;

&lt;p&gt;原文：&lt;a href=&quot;https://www.adexchanger.com/data-exchanges/cloud-based-collaboration-is-ad-techs-post-cookie-lifeline-but-will-it-last/&quot;&gt;Cloud-Based Collaboration Is Ad Tech’s Post-Cookie Lifeline – But Will It Last?&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;更多参考&quot;&gt;更多参考&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/cn/clean-rooms/&quot;&gt;AWS Clean rooms介绍 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/cn/solutions/advertising-marketing/data-clean-rooms/&quot;&gt;基于AWS Clean rooms的解决方案&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 11 Mar 2024 00:00:00 -0500</pubDate>
        <link>https://magicwind.top/adtech/2024/03/11/post-cookie-clean-room/</link>
        <guid isPermaLink="true">https://magicwind.top/adtech/2024/03/11/post-cookie-clean-room/</guid>
        
        
        <category>adtech</category>
        
      </item>
    
      <item>
        <title>GPT-3.5 Turbo的模型微调现在可用</title>
        <description>&lt;p&gt;GPT-3.5 Turbo的微调现在可用，GPT-4的微调将在今年秋季推出。此更新使开发人员能够定制更适合他们用例的模型，并大规模运行这些定制模型。早期测试表明，GPT-3.5 Turbo的微调版本可以在某些狭窄任务上匹配甚至超过基础GPT-4级别的能力。与我们所有的API一样，微调API的输入和输出数据由客户拥有，OpenAI或任何其他组织都不使用它来训练其他模型。&lt;/p&gt;

&lt;h2 id=&quot;微调用例&quot;&gt;微调用例&lt;/h2&gt;
&lt;p&gt;自GPT-3.5 Turbo发布以来，开发人员和企业一直在要求能够定制该模型，为他们的用户创建独特和差异化的体验。通过此次推出，开发人员现在可以运行监督微调，使此模型更好地适应他们的用例。&lt;/p&gt;

&lt;p&gt;在我们的私人测试版中，微调客户已能够在常见用例上有意义地提高模型性能，例如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;改进的可操纵性&lt;/strong&gt;：微调允许企业使模型更好地遵循指令，例如使输出简练或始终以给定语言响应。例如，开发人员可以使用微调确保模型在被提示使用该语言时始终以德语响应。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;可靠的输出格式化&lt;/strong&gt;：微调提高了模型一致地格式化响应的能力——这对于需要特定响应格式的应用程序（例如代码完成或组装API调用）至关重要。开发人员可以使用微调更可靠地将用户提示转换为可以与他们自己的系统一起使用的高质量JSON片段。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;定制语调&lt;/strong&gt;：微调是一种改善模型输出（例如其语调）的定性感觉的好方法，使其更符合企业品牌的声音。具有可识别品牌声音的企业可以使用微调使模型与其语调更一致。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;除了性能增加之外，微调还使企业能够在确保类似性能的同时&lt;strong&gt;缩短提示&lt;/strong&gt;。使用GPT-3.5-Turbo的微调还可以处理4k个令牌——是我们之前微调模型的两倍。通过将指令微调到模型本身，早期测试人员已将提示大小减少了多达90%，从而加速了每个API调用并降低了成本。&lt;/p&gt;

&lt;p&gt;与诸如提示工程、信息检索和函数调用等其他技术结合使用时，微调最为强大。查看我们的微调指南以了解更多信息。函数调用和gpt-3.5-turbo-16k的微调支持将在今年秋季晚些时候推出。&lt;/p&gt;

&lt;h2 id=&quot;微调步骤&quot;&gt;微调步骤&lt;/h2&gt;

&lt;h3 id=&quot;步骤1-准备数据&quot;&gt;步骤1 准备数据&lt;/h3&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;messages&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;role&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;system&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;content&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;You are an assistant that occasionally misspells words&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;role&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;user&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;content&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Tell me a story.&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;role&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;assistant&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;content&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;One day a student went to schoool.&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;步骤2-上传数据&quot;&gt;步骤2 上传数据&lt;/h3&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl &lt;span class=&quot;nt&quot;&gt;-https&lt;/span&gt;://api.openai.com/v1/files &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Authorization: Bearer &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$OPENAI_API_KEY&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;-F&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;purpose=fine-tune&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;-F&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;file=@path_to_your_file&quot;&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;步骤3-创建一个微调作业&quot;&gt;步骤3 创建一个微调作业&lt;/h3&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl https://api.openai.com/v1/fine_tuning/jobs &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Content-Type: application/json&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Authorization: Bearer &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$OPENAI_API_KEY&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;{
  &quot;training_file&quot;: &quot;TRAINING_FILE_ID&quot;,
  &quot;model&quot;: &quot;gpt-3.5-turbo-0613&quot;,
}&apos;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;一旦模型完成微调过程，它就可以立即在生产中使用，并具有与底层模型相同的共享速率限制。&lt;/p&gt;

&lt;h3 id=&quot;步骤4-使用微调过的模型&quot;&gt;步骤4 使用微调过的模型&lt;/h3&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl https://api.openai.com/v1/chat/completions &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Content-Type: application/json&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Authorization: Bearer &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$OPENAI_API_KEY&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;{
  &quot;model&quot;: &quot;ft:gpt-3.5-turbo:org_id&quot;,
  &quot;messages&quot;: [
    {
      &quot;role&quot;: &quot;system&quot;,
      &quot;content&quot;: &quot;You are an assistant that occasionally misspells words&quot;
    },
    {
      &quot;role&quot;: &quot;user&quot;,
      &quot;content&quot;: &quot;Hello! What is fine-tuning?&quot;
    }
  ]
}&apos;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我们还将在近期推出一款微调用户界面（UI），这将使开发人员更容易访问有关正在进行的微调作业、已完成的模型快照等信息。&lt;/p&gt;

&lt;h2 id=&quot;安全性&quot;&gt;安全性&lt;/h2&gt;
&lt;p&gt;确保微调的部署安全对我们非常重要。为了通过微调过程保留默认模型的安全功能，微调训练数据将通过我们的审核API和GPT-4驱动的审核系统传递，以检测与我们的安全标准冲突的不安全训练数据。&lt;/p&gt;

&lt;h2 id=&quot;定价&quot;&gt;定价&lt;/h2&gt;
&lt;p&gt;微调成本分为两个部分：初始训练成本和使用成本：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;训练：$0.008 / 1K 令牌&lt;/li&gt;
  &lt;li&gt;使用输入：$0.012 / 1K 令牌&lt;/li&gt;
  &lt;li&gt;使用输出：$0.016 / 1K 令牌&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;例如，一个训练文件为100,000令牌，训练3个epochs的gpt-3.5-turbo微调作业预计费用为$2.40。&lt;/p&gt;

&lt;h2 id=&quot;更新的gpt-3模型&quot;&gt;更新的GPT-3模型&lt;/h2&gt;
&lt;p&gt;在7月，我们宣布原始的GPT-3基础模型（ada、babbage、curie和davinci）将在2024年1月4日关闭。今天，我们将babbage-002和davinci-002作为这些模型的替代品推出，无论是作为基础模型还是微调模型。客户可以通过查询Completions API来访问这些模型。&lt;/p&gt;

&lt;p&gt;这些模型可以通过我们的新API端点/v1/fine_tuning/jobs进行微调。这个新端点提供了分页和更多的可扩展性，以支持微调API的未来演变。从/v1/fine-tunes过渡到更新的端点非常简单，我们的新微调指南中可以找到更多详细信息。这将弃用旧的/v1/fine-tunes端点，该端点将在2024年1月4日关闭。&lt;/p&gt;
</description>
        <pubDate>Wed, 23 Aug 2023 00:00:00 -0500</pubDate>
        <link>https://magicwind.top/openai/2023/08/23/gpt3.5-fine-tune/</link>
        <guid isPermaLink="true">https://magicwind.top/openai/2023/08/23/gpt3.5-fine-tune/</guid>
        
        
        <category>openai</category>
        
      </item>
    
      <item>
        <title>如何微调大模型?</title>
        <description>&lt;h1 id=&quot;微调&quot;&gt;微调&lt;/h1&gt;
&lt;p&gt;学习如何为您的应用定制模型。&lt;/p&gt;

&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;微调使您通过提供以下功能从API可用的模型中获得更多优势：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;比提示设计更高质量的结果&lt;/li&gt;
  &lt;li&gt;能够在提示中容纳的示例之外进行训练&lt;/li&gt;
  &lt;li&gt;由于提示较短而节省令牌&lt;/li&gt;
  &lt;li&gt;请求延迟更低&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;GPT-3已在开放互联网上的大量文本上进行了预训练。当给出一个只有几个例子的提示时，它通常可以直观地了解您试图执行的任务，并生成一个合理的完成。这通常被称为“少数样本学习”。&lt;/p&gt;

&lt;p&gt;通过在提示中容纳的许多更多示例上训练，微调改善了少数样本学习，让您在许多任务上取得更好的效果。一旦模型被微调，您将不再需要在提示中提供示例。这节省了成本，并实现了更低延迟的请求。&lt;/p&gt;

&lt;p&gt;从高层次来看，微调涉及以下步骤：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;准备和上传训练数据&lt;/li&gt;
  &lt;li&gt;训练一个新的微调模型&lt;/li&gt;
  &lt;li&gt;使用您的微调模型&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;哪些模型可以进行微调&quot;&gt;哪些模型可以进行微调？&lt;/h2&gt;

&lt;p&gt;微调目前仅适用于以下基本模型：davinci、curie、babbage和ada。这些是不进行任何指令后训练的原始模型（例如text-davinci-003）。您还可以继续微调一个已经微调过模型，以添加额外的数据，而无需从头开始。&lt;/p&gt;

&lt;h2 id=&quot;安装&quot;&gt;安装&lt;/h2&gt;
&lt;p&gt;我们推荐使用OpenAI的命令行界面（CLI）。要安装它，请运行&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip install --upgrade openai&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;（以下指令适用于0.9.4及更高版本。此外，OpenAI CLI需要python 3。）&lt;/p&gt;

&lt;p&gt;通过在您的shell初始化脚本（例如.bashrc、zshrc等）中添加以下行或在微调命令之前在命令行中运行它，设置您的OPENAI_API_KEY环境变量：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;OPENAI_API_KEY&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&amp;lt;OPENAI_API_KEY&amp;gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;准备训练数据&quot;&gt;准备训练数据&lt;/h2&gt;

&lt;p&gt;训练数据是您教GPT-3您想让它说什么的方式。&lt;/p&gt;

&lt;p&gt;您的数据必须是JSONL文档，其中每一行都是一个提示完成对，对应一个训练示例。您可以使用我们的CLI数据准备工具轻松将您的数据转换为此文件格式。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-jsonl&quot;&gt;{&quot;prompt&quot;: &quot;&amp;lt;prompt text&amp;gt;&quot;, &quot;completion&quot;: &quot;&amp;lt;ideal generated text&amp;gt;&quot;}
{&quot;prompt&quot;: &quot;&amp;lt;prompt text&amp;gt;&quot;, &quot;completion&quot;: &quot;&amp;lt;ideal generated text&amp;gt;&quot;}
{&quot;prompt&quot;: &quot;&amp;lt;prompt text&amp;gt;&quot;, &quot;completion&quot;: &quot;&amp;lt;ideal generated text&amp;gt;&quot;}
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;为微调设计您的提示和完成与为我们的基本模型（Davinci、Curie、Babbage、Ada）使用设计您的提示不同。特别是，虽然基本模型的提示通常包括多个示例（“少数样本学习”），但对于微调，每个训练示例通常由单个输入示例及其关联输出组成，无需给出详细指令或在同一提示中包括多个示例。&lt;/p&gt;

&lt;p&gt;有关如何为各种任务准备训练数据的更详细指导，请参考我们&lt;a href=&quot;https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset&quot;&gt;准备数据集&lt;/a&gt;的最佳实践。&lt;/p&gt;

&lt;p&gt;您拥有的训练示例越多越好。我们建议至少有几百个示例。总的来说，我们发现数据集大小每增加一倍都会导致模型质量的线性提高。&lt;/p&gt;

&lt;h3 id=&quot;cli数据准备工具&quot;&gt;CLI数据准备工具&lt;/h3&gt;

&lt;p&gt;我们开发了一个工具，用于验证、提供建议并重新格式化您的数据：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;openai tools fine_tunes.prepare_data -f &amp;lt;LOCAL_FILE&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;此工具接受不同的格式，唯一的要求是它们必须包含提示和完成列/键。您可以传递&lt;strong&gt;CSV、TSV、XLSX、JSON&lt;/strong&gt;或&lt;strong&gt;JSONL&lt;/strong&gt;文件，它将在引导您完成建议更改的过程后将输出保存为准备进行微调的JSONL文件。&lt;/p&gt;

&lt;h2 id=&quot;创建一个微调模型&quot;&gt;创建一个微调模型&lt;/h2&gt;

&lt;p&gt;以下假设您已经按照上述指导准备了训练数据。&lt;/p&gt;

&lt;p&gt;使用OpenAI CLI开始您的微调工作：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;openai api fine_tunes.create -t &amp;lt;TRAIN_FILE_ID_OR_PATH&amp;gt; -m &amp;lt;BASE_MODEL&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;其中BASE_MODEL是您开始的基本模型的名称（ada、babbage、curie或davinci）。您可以使用&lt;a href=&quot;https://platform.openai.com/docs/guides/fine-tuning/customize-your-model-name&quot;&gt;后缀参数&lt;/a&gt;自定义微调模型的名称。&lt;/p&gt;

&lt;p&gt;执行上述命令会做几件事情：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;使用files API上传文件（或使用已经上传的文件）&lt;/li&gt;
  &lt;li&gt;创建微调作业&lt;/li&gt;
  &lt;li&gt;流式传输事件，直到工作完成（这通常需要几分钟，但如果队列中有很多工作或您的数据集很大，则可能需要几小时）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;每个微调工作都是从基本模型开始的，默认为curie。模型的选择会影响模型的性能和运行微调模型的成本。您的模型可以是：ada、babbage、curie或davinci。&lt;/p&gt;

&lt;p&gt;在您开始微调作业后，可能需要一些时间才能完成。您的工作可能会排在我们系统上的其他工作之后，根据模型和数据集的大小，训练我们的模型可能需要几分钟或几小时。如果由于任何原因事件流被中断，您可以通过运行以下命令恢复它：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;openai api fine_tunes.follow -i &amp;lt;YOUR_FINE_TUNE_JOB_ID&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;当工作完成时，它应显示微调模型的名称。&lt;/p&gt;

&lt;p&gt;除了创建微调作业，您还可以列出现有作业，检索作业状态或取消作业。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 列出所有创建的微调
openai api fine_tunes.list

# 检索微调的状态。结果对象包括
# 工作状态（可能是pending、running、succeeded或failed之一）
# 和其他信息
openai api fine_tunes.get -i &amp;lt;YOUR_FINE_TUNE_JOB_ID&amp;gt;

# 取消工作
openai api fine_tunes.cancel -i &amp;lt;YOUR_FINE_TUNE_JOB_ID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;使用微调模型&quot;&gt;使用微调模型&lt;/h2&gt;
&lt;p&gt;当工作成功后，fine_tuned_model字段将填充模型的名称。您现在可以将此模型指定为我们的Completions API的参数，并使用Playground向其发出请求。&lt;/p&gt;

&lt;p&gt;在您的工作首次完成后，您的模型可能需要几分钟才能准备好处理请求。如果对您的模型的完成请求超时，可能是因为您的模型仍在加载。如果发生这种情况，请在几分钟后重试。&lt;/p&gt;

&lt;p&gt;您可以通过将模型名称作为完成请求的model参数传递来开始发出请求：&lt;/p&gt;

&lt;p&gt;OpenAI CLI:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;openai api completions.create -m &amp;lt;FINE_TUNED_MODEL&amp;gt; -p &amp;lt;YOUR_PROMPT&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;cURL:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-curl&quot;&gt;curl https://api.openai.com/v1/completions \
  -H &quot;Authorization: Bearer $OPENAI_API_KEY&quot; \
  -H &quot;Content-Type: application/json&quot; \
  -d &apos;{&quot;prompt&quot;: YOUR_PROMPT, &quot;model&quot;: FINE_TUNED_MODEL}&apos;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Python:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;openai&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;openai&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Completion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FINE_TUNED_MODEL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;YOUR_PROMPT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Node.js:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-nodejs&quot;&gt;const response = await openai.createCompletion({
  model: FINE_TUNED_MODEL
  prompt: YOUR_PROMPT,
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;您可以继续在这些针对微调模型的请求上使用所有其他&lt;a href=&quot;https://platform.openai.com/docs/api-reference/completions&quot;&gt;Completions&lt;/a&gt;参数，例如temperature、frequency_penalty、presence_penalty等。&lt;/p&gt;

&lt;h2 id=&quot;删除微调模型&quot;&gt;删除微调模型&lt;/h2&gt;

&lt;p&gt;要删除一个微调模型，您必须被指定为您组织内的“所有者”。&lt;/p&gt;

&lt;p&gt;OpenAI CLI:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;openai api models.delete -i &amp;lt;FINE_TUNED_MODEL&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;cURL:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -X &quot;DELETE&quot; https://api.openai.com/v1/models/&amp;lt;FINE_TUNED_MODEL&amp;gt; \
  -H &quot;Authorization: Bearer $OPENAI_API_KEY&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Python:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import openai
openai.Model.delete(FINE_TUNED_MODEL)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;准备您的数据集&quot;&gt;准备您的数据集&lt;/h1&gt;

&lt;p&gt;微调是一种强大的技术，用于创建特定于您用例的新模型。&lt;strong&gt;在微调模型之前，我们强烈建议阅读以下您用例的最佳实践和具体指导方针。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;数据格式化&quot;&gt;数据格式化&lt;/h2&gt;

&lt;p&gt;要微调模型，您需要一组训练示例，每个示例都由单个输入（“提示”）和其关联输出（“完成”）组成。这与使用我们的基本模型显著不同，在那里您可能在单个提示中输入详细说明或多个示例。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;每个提示应以固定分隔符结尾，以通知模型提示何时结束，完成何时开始。通常效果良好的简单分隔符是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\n\n###\n\n&lt;/code&gt;。分隔符不应出现在任何提示的其他地方。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;由于我们的标记化，每个完成应以空格开始，这将大多数单词与前导空格标记化。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;每个完成都应以固定的停止序列结尾，以通知模型完成何时结束。停止序列可以是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;\n&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;###&lt;/code&gt;或任何不出现在任何完成中的其他令牌。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对于推断，您应该以与创建训练数据集时相同的方式格式化提示，包括相同的分隔符。还要指定相同的停止序列以正确截断完成。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;一般最佳实践&quot;&gt;一般最佳实践&lt;/h2&gt;

&lt;p&gt;微调的性能随着更多高质量示例的增加而提高。要微调一个比使用我们的基本模型与高质量提示的表现更好的模型，您应该提供至少几百个高质量示例，理想情况下由人类专家审核。从那里开始，性能倾向于随着示例数量加倍而线性增加。增加示例数量通常是提高性能的最佳和最可靠的方法。&lt;/p&gt;

&lt;p&gt;分类器是最容易上手的模型。对于分类问题，我们建议使用ada，该模型通常倾向于在微调后的性能只比更有能力的模型稍差一点，同时速度明显更快且更便宜。&lt;/p&gt;

&lt;p&gt;如果您是在现有数据集上微调而不是从头开始编写提示，请务必人工审查数据以排除冒犯或不准确的内容（如果可能的话），或者尽可能审查数据集的许多随机样本（如果数据集很大）。&lt;/p&gt;

&lt;p&gt;(未完待续)&lt;/p&gt;
</description>
        <pubDate>Tue, 08 Aug 2023 00:00:00 -0500</pubDate>
        <link>https://magicwind.top/openai/2023/08/08/openai-fine-tuning/</link>
        <guid isPermaLink="true">https://magicwind.top/openai/2023/08/08/openai-fine-tuning/</guid>
        
        
        <category>openai</category>
        
      </item>
    
      <item>
        <title>如何搭建jekyll环境</title>
        <description>&lt;p&gt;Linux OS: Ubuntu, Debian (root user)&lt;/p&gt;

&lt;h2 id=&quot;install-ruby-using-rvm&quot;&gt;Install Ruby Using RVM&lt;/h2&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;apt update
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;apt-get &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;gnupg2
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gpg2 &lt;span class=&quot;nt&quot;&gt;--keyserver&lt;/span&gt; keyserver.ubuntu.com &lt;span class=&quot;nt&quot;&gt;--recv-keys&lt;/span&gt; 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\c&lt;/span&gt;url &lt;span class=&quot;nt&quot;&gt;-sSL&lt;/span&gt; https://get.rvm.io | bash &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; stable
Downloading https://github.com/rvm/rvm/archive/1.29.12.tar.gz
Downloading https://github.com/rvm/rvm/releases/download/1.29.12/1.29.12.tar.gz.asc
gpg: Signature made Sat Jan 16 02:46:22 2021 CST
gpg:                using RSA key 7D2BAF1CF37B13E2069D6956105BD0E739499BDB
gpg: Good signature from &lt;span class=&quot;s2&quot;&gt;&quot;Piotr Kuczynski &amp;lt;piotr.kuczynski@gmail.com&amp;gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;unknown]
gpg: WARNING: This key is not certified with a trusted signature!
gpg:          There is no indication that the signature belongs to the owner.
Primary key fingerprint: 7D2B AF1C F37B 13E2 069D  6956 105B D0E7 3949 9BDB
GPG verified &lt;span class=&quot;s1&quot;&gt;&apos;/usr/local/rvm/archives/rvm-1.29.12.tgz&apos;&lt;/span&gt;
Creating group &lt;span class=&quot;s1&quot;&gt;&apos;rvm&apos;&lt;/span&gt;
Installing RVM to /usr/local/rvm/
Installation of RVM &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; /usr/local/rvm/ is almost &lt;span class=&quot;nb&quot;&gt;complete&lt;/span&gt;:

  &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; First you need to add all &lt;span class=&quot;nb&quot;&gt;users &lt;/span&gt;that will be using rvm to &lt;span class=&quot;s1&quot;&gt;&apos;rvm&apos;&lt;/span&gt; group,
    and &lt;span class=&quot;nb&quot;&gt;logout&lt;/span&gt; - login again, anyone using rvm will be operating with &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;umask &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;rwx,g&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;rwx,o&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;rx&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; To start using RVM you need to run &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; /etc/profile.d/rvm.sh&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;all your open shell windows, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;rare cases you need to reopen all shell windows.
  &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; Please &lt;span class=&quot;k&quot;&gt;do &lt;/span&gt;NOT forget to add your &lt;span class=&quot;nb&quot;&gt;users &lt;/span&gt;to the rvm group.
     The installer no longer auto-adds root or &lt;span class=&quot;nb&quot;&gt;users &lt;/span&gt;to the rvm group. Admins must &lt;span class=&quot;k&quot;&gt;do &lt;/span&gt;this.
     Also, please note that group memberships are ONLY evaluated at login time.
     This means that &lt;span class=&quot;nb&quot;&gt;users &lt;/span&gt;must log out &lt;span class=&quot;k&quot;&gt;then &lt;/span&gt;back &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;before group membership takes effect!
  &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; WARNING:  version This account is currently not available. detected - Zsh 4.3.12 / 5.0.0+ is recommended,
     with current one errors to be expected - bugs &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;shell code interpretation.
Thanks &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;installing RVM 🙏

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; /etc/profile.d/rvm.sh
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;rvm &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;ruby-3.2.2&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;install-ruby-using-rbenv&quot;&gt;Install Ruby Using Rbenv&lt;/h2&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;apt update
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;apt &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;git curl autoconf bison build-essential libssl-dev libyaml-dev libreadline6-dev &lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;zlib1g-dev libncurses5-dev libffi-dev libgdbm6 libgdbm-dev libdb-dev
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-fsSL&lt;/span&gt; https://github.com/rbenv/rbenv-installer/raw/HEAD/bin/rbenv-installer | bash

&lt;span class=&quot;c&quot;&gt;# Bash&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;export PATH=&quot;$HOME/.rbenv/bin:$PATH&quot;&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ~/.bashrc
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;eval &quot;$(rbenv init -)&quot;&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ~/.bashrc
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; ~/.bashrc

&lt;span class=&quot;c&quot;&gt;# Zsh&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;export PATH=&quot;$HOME/.rbenv/bin:$PATH&quot;&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ~/.zshrc
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;eval &quot;$(rbenv init -)&quot;&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ~/.zshrc
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; ~/.zshrc

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;rbenv &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;rbenv &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;rbenv &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;3.2.2
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;rbenv global 3.2.2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;install-gems&quot;&gt;Install Gems&lt;/h2&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gem install bundler jekyll
bundle install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Thu, 13 Jul 2023 00:00:00 -0500</pubDate>
        <link>https://magicwind.top/jekyll/2023/07/13/setup-jekyll-env/</link>
        <guid isPermaLink="true">https://magicwind.top/jekyll/2023/07/13/setup-jekyll-env/</guid>
        
        
        <category>jekyll</category>
        
      </item>
    
      <item>
        <title>跟着GPT学习自然语言处理之text2vec</title>
        <description>&lt;h2 id=&quot;跟着gpt学习自然语言处理之text2vec&quot;&gt;跟着GPT学习自然语言处理之text2vec&lt;/h2&gt;

&lt;h2 id=&quot;q-什么是word2vec&quot;&gt;Q: 什么是word2vec?&lt;/h2&gt;
&lt;p&gt;A: Word2Vec是一种流行的词嵌入（word embedding）方法，它可以产生高质量的词向量。Word2Vec是由Google的研究员在2013年开发的，用于学习语义上有意义的词向量。&lt;/p&gt;

&lt;p&gt;词嵌入方法的基本思想是将单词或短语从词汇表中映射到向量空间。这样，语义上相似的单词在向量空间中的位置就会接近。&lt;/p&gt;

&lt;p&gt;Word2Vec模型有两种主要的训练算法：连续词袋模型（CBOW）和Skip-gram模型。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;连续词袋模型（CBOW）&lt;/strong&gt;：CBOW模型预测目标词（中心词）根据其周围的词（上下文）。比如给定上下文词”the cat sits on the”, CBOW模型尝试预测目标词”mat”。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Skip-gram模型&lt;/strong&gt;：Skip-gram模型是CBOW的逆操作，它尝试预测上下文单词根据目标词（中心词）。比如给定目标词”mat”, Skip-gram模型尝试预测上下文词”the cat sits on the”。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这两种模型都有各自的优点：CBOW模型对于小型数据集表现较好，而Skip-gram模型对于大型数据集和罕见单词的处理上效果更好。&lt;/p&gt;

&lt;p&gt;Word2Vec通过将词语转换为向量形式，使得我们可以用计算余弦相似度等方式来计算词语间的语义相似度，或者进行词语的类比推理等操作。例如，Word2Vec可以发现”king”和”queen”，”man”和”woman”等单词间的相似关系。&lt;/p&gt;

&lt;h2 id=&quot;q-如何用python训练word2vec模型&quot;&gt;Q: 如何用python训练word2vec模型？&lt;/h2&gt;
&lt;p&gt;A: 训练一个Word2Vec模型是相对直接的，你可以使用Python的gensim库来进行。以下是一个基本的步骤流程：&lt;/p&gt;

&lt;p&gt;首先，确保你已经安装了必要的库，你可以使用pip来安装：&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gensim&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;以下是训练一个Word2Vec模型的简单例子：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 导入必要的库
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gensim.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 假设我们有以下的语料
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;the&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;word2vec&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
             &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;the&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
             &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;yet&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;another&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
             &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;one&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;more&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
             &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;and&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;the&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;final&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 初始化和训练模型
# 参数min_count会忽略所有出现频率小于这个值的单词
# 参数size是词向量的维度
# 参数window是句子中当前词和预测词之间的最大距离
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Word2Vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 你可以保存训练好的模型
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;word2vec.model&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 加载模型
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;word2vec.model&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 访问词向量
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 找到最相似的词
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;similar_words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;most_similar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;注意这只是一个简单的例子，实际使用中，你需要大量的语料来训练模型。而且，你可能需要调整Word2Vec的参数，如训练迭代次数、窗口大小、词向量维度等，以得到最佳的模型。&lt;/p&gt;

&lt;p&gt;最后，需要注意的是，即使训练过程非常耗时，但训练后的模型可以被保存，以供未来使用。&lt;/p&gt;

&lt;h2 id=&quot;q-如何评估word2vec模型的效果&quot;&gt;Q: 如何评估word2vec模型的效果？&lt;/h2&gt;
&lt;p&gt;A: 评估Word2Vec模型的性能通常涉及到以下几个方面：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;语义和句法的类比任务&lt;/strong&gt;：这是一种常见的评估词嵌入模型的方法，例如，“king”到“queen”类比于“man”到“woman”。在这种情况下，我们期望模型能够正确地找出对应的词。Mikolov等人在他们的Word2Vec论文中提出了一个包含语义和句法类比的测试集。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;词义相似度任务&lt;/strong&gt;：在这种任务中，模型需要对一对词的相似性给出评分，然后这个评分会和人工标注的相似度进行比较。一些公开的数据集，如WordSim-353，SimLex-999等，可以用来进行此类评估。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;在下游任务中的表现&lt;/strong&gt;：这可能是最直接和最重要的评估方法。你可以将预训练的词向量用于特定的NLP任务，如文本分类、情感分析、命名实体识别（NER）等，看看它是否能提高模型的性能。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;可视化&lt;/strong&gt;：虽然这不是定量评估的方法，但通过将高维的词向量降维（如使用t-SNE等方法）到2D或3D并进行可视化，可以帮助我们直观地理解词向量的空间结构，看看语义相近的词是否在空间中聚集在一起。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;值得注意的是，这些评估方法并不能完全代表模型的质量。在实际应用中，你需要根据具体任务的需求来选择和优化模型。&lt;/p&gt;

&lt;h2 id=&quot;q-如何用python代码实现一个评估自己训练的word2vec模型的效果&quot;&gt;Q: 如何用Python代码实现一个评估自己训练的word2vec模型的效果？&lt;/h2&gt;
&lt;p&gt;A: 在Python中，你可以使用gensim的Word2Vec模型和Scikit-learn库来评估你的模型。以下是一种可能的方法。&lt;/p&gt;

&lt;p&gt;首先，你可以使用gensim提供的函数来评估模型在词类比任务上的表现：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 加载你的模型
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gensim.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;word2vec.model&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 使用gensim的词类比评估
# 输入是形如 &quot;man woman king queen&quot; 的类比对
# 第一个词对应的类比应该等于第二个词对应的类比
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;analogies_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;evaluate_word_analogies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;questions-words.txt&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;其中’questions-words.txt’是一个包含词类比的测试集。你可以在这里找到这个文件：https://github.com/tmikolov/word2vec/blob/master/questions-words.txt&lt;/p&gt;

&lt;p&gt;对于词义相似度任务，你需要一个人工标注的相似度数据集。然后，你可以计算模型给出的相似度和人工标注的相似度之间的皮尔森相关系数或者斯皮尔曼等级相关系数：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.stats&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pearsonr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spearmanr&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 假设你有一些单词对和他们的相似度分数
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_pairs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;woman&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;man&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;car&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;bike&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (word1, word2, human_score)
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;similarity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_pairs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;human_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_pairs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 计算皮尔森相关系数
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pearson_corr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pearsonr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;human_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 计算斯皮尔曼等级相关系数
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spearman_corr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;spearmanr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;human_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;对于下游任务，你需要有一个特定任务的数据集。你可以将Word2Vec模型的输出作为特征输入到一个机器学习模型中（如SVM，逻辑回归等），然后评估这个模型的性能。&lt;/p&gt;

&lt;p&gt;请注意，这只是一种可能的方法，实际的评估方法可能需要根据你的任务和数据来调整。&lt;/p&gt;

&lt;h2 id=&quot;q-如何用python代码实现通过可视化方式来评估word2vec方法训练出来的模型的效果&quot;&gt;Q: 如何用python代码实现：通过可视化方式来评估word2vec方法训练出来的模型的效果？&lt;/h2&gt;
&lt;p&gt;A: 为了将高维度的词向量可视化，我们通常会用到降维的方法，例如PCA (Principal Component Analysis) 或者t-SNE (t-Distributed Stochastic Neighbor Embedding)。以下是一个使用gensim库训练Word2Vec模型并用t-SNE进行可视化的例子：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gensim.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Word2Vec&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn.manifold&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TSNE&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 训练Word2Vec模型
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;the&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;word2vec&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;the&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;yet&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;another&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;one&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;more&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;and&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;the&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;final&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Word2Vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 获取词向量
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_vectors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wv&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 用t-SNE进行降维
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tsne&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TSNE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;word_vectors_2d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tsne&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_vectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index_to_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 绘制图像
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_vectors_2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_vectors_2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 为每个点添加词语标签
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coord&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index_to_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_vectors_2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coord&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在这个例子中，我们将每个词的词向量用t-SNE降维到2维，然后在平面上绘制出来，并为每个点添加了对应的词语标签。注意到在实际应用中，你可能需要对大量的词向量进行降维和可视化，这可能需要大量的计算资源。&lt;/p&gt;

&lt;h2 id=&quot;q-如何用python对中文文本进行分词操作&quot;&gt;Q: 如何用Python对中文文本进行分词操作？&lt;/h2&gt;
&lt;p&gt;A: 在处理中文文本的时候，我们通常需要进行分词，因为中文文本的词与词之间没有像英文那样的空格分隔。以下是两种常见的中文分词库的使用方法：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;jieba库&lt;/strong&gt;：jieba是一个非常流行的中文分词库，支持三种分词模式：精确模式、全模式和搜索引擎模式。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;安装jieba:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jieba&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;使用jieba:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jieba&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;我爱北京天安门&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 精确模式，试图将句子最精确地切开，适合文本分析
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jieba&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cut_all&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;精确模式: &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/ &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 全模式，把句子中所有的可以成词的词语都扫描出来
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jieba&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cut_all&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;全模式: &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/ &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jieba&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cut_for_search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;搜索引擎模式: &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/ &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;pkuseg库&lt;/strong&gt;：pkuseg是北京大学发布的一款中文分词工具，针对微博、混合长短句等非规范文本有更好的分词效果。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;安装pkuseg:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pkuseg&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;使用pkuseg:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pkuseg&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;我爱北京天安门&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;seg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pkuseg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;pkuseg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这些分词工具都可以进行自定义词典的添加，能更好地适应特定领域的分词需求。你可以根据需要选择最适合的工具和模式进行中文分词。&lt;/p&gt;
</description>
        <pubDate>Thu, 13 Jul 2023 00:00:00 -0500</pubDate>
        <link>https://magicwind.top/gpt/2023/07/13/learn-nlp-with-gpt-s1-text2vec/</link>
        <guid isPermaLink="true">https://magicwind.top/gpt/2023/07/13/learn-nlp-with-gpt-s1-text2vec/</guid>
        
        
        <category>gpt</category>
        
      </item>
    
      <item>
        <title>GPT-4 API正式发布和Completions API中废弃了旧模型</title>
        <description>&lt;p&gt;GPT-3.5 Turbo，DALL·E和Whisper API也已发布，我们正在发布Completions API的旧模型的废弃计划，这些模型将在2024年初退役。&lt;/p&gt;

&lt;p&gt;从今天开始，所有付费API客户都可以访问GPT-4。在3月，我们推出了ChatGPT API，而在本月初，我们发布了对基于聊天的模型的第一次更新。我们设想未来基于聊天的模型可以支持任何用例。今天，我们正在宣布对Completions API的旧模型的废弃计划，并建议用户采用Chat Completions API。&lt;/p&gt;

&lt;h2 id=&quot;gpt-4-api普遍可用性&quot;&gt;GPT-4 API普遍可用性&lt;/h2&gt;

&lt;p&gt;GPT-4是我们最有能力的模型。自3月以来，数百万开发者已经请求访问GPT-4 API，而利用GPT-4的创新产品的范围每天都在增长。今天，所有现有的有成功支付历史的API开发者都可以访问具有8K上下文的GPT-4 API。我们计划在本月底向新开发者开放访问权限，然后根据计算可用性开始提高速率限制。&lt;/p&gt;

&lt;p&gt;基于这些模型对生产规模使用的稳定性和准备情况，我们还将GPT-3.5 Turbo，DALL·E和Whisper API普遍可用。我们正在努力为GPT-4和GPT-3.5 Turbo安全地启用微调，并期望今年晚些时候提供此功能。&lt;/p&gt;

&lt;h2 id=&quot;从文本补全转向聊天补全&quot;&gt;从文本补全转向聊天补全&lt;/h2&gt;

&lt;p&gt;我们在3月引入了Chat Completions API，现在它占据了我们API GPT使用的97%。&lt;/p&gt;

&lt;p&gt;最初的Completions API是在2020年6月引入的，用于提供与我们的语言模型交互的自由形式文本提示。我们已经了解到，我们通常可以通过更结构化的提示接口提供更好的结果。基于聊天的范式已被证明是强大的，能够处理大多数以前的用例和新的对话需求，同时提供更高的灵活性和特异性。特别是，Chat Completions API的结构化接口（例如，系统消息，函数调用）和多轮对话能力使开发者能够构建对话体验和广泛的完成任务。它还有助于降低提示注入攻击的风险，因为用户提供的内容可以从指令中结构化地分离出来。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;文本总结&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;系统(System)
将此消息总结为最多10个字。

用户(User)
木星是太阳系中离太阳第五远和最大的行星。它是一个气体巨大行星，质量是太阳的千分之一，但是是太阳系中所有其他行星总和的两倍半。木星是夜空中肉眼可见的最亮的物体之一，自记录历史以前就为古代文明所知。它以罗马神木星命名。从地球上看，木星可以足够明亮，以至于其反射的光可以投射出可见的阴影，平均而言，它是夜空中继月亮和金星之后的第三亮的自然物体。

助手(Assistant)
木星：最大的行星，夜晚肉眼可见。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;代码完成&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;System
Complete the following code.

User
def fibonacci(num):

Assistant
if num == 0:
    return 0
elif num == 1:
    return 1
else:
    fib = [0, 1]
    for i in range(2, num + 1):
          fib.append(fib[i-1] + fib[i-2])
    return fib[num]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Few-shot learning&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;System
You translate corporate jargon into plain English.

User
New synergies will help drive top-line growth.

Assistant
Working well together will make more money.

User
Let’s circle back when we have more bandwidth to touch base on opportunities for increased leverage.

Assistant
When we’re less busy, let’s talk about how to do better.

User
This late pivot means we don’t have time to boil the ocean for the client deliverable.

Assistant
Because of this sudden change, we don’t have enough time to complete the entire project for the client.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我们计划继续投入大部分平台努力在这个方向，因为我们相信它将为开发者提供越来越有能力和易于使用的体验。我们正在努力快速关闭Chat Completions API的最后几个剩余的缺口，例如完成令牌的对数概率和增加可操纵性以减少响应的“聊天性”。&lt;/p&gt;

&lt;h2 id=&quot;废弃completions-api中的旧模型&quot;&gt;废弃Completions API中的旧模型&lt;/h2&gt;

&lt;p&gt;作为我们在Chat Completions API中增加投资和我们优化计算能力的努力的一部分，6个月后，我们将退役使用Completions API的一些旧模型。虽然这个API将保持可访问，但我们将从今天开始在我们的开发者文档中将其标记为“遗留”。我们计划将未来的模型和产品改进集中在Chat Completions API上，并且没有计划公开发布使用Completions API的新模型。&lt;/p&gt;

&lt;p&gt;从2024年1月4日开始，旧的完成模型将不再可用，并将被以下模型替换：&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;旧模型                 新模型
ada                   ada-002
babbage               babbage-002
curie                 curie-002
davinci               davinci-002

davinci-instruct-bete
curie-instruct-beta
text-ada-001
text-babbage-001
text-curie-001
text-davinci-001
text-davinci-002
text-davinci-003
--&amp;gt; gpt-3.5-turbo-instruct
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;使用基础GPT-3模型的稳定模型名称（ada，babbage，curie，davinci）的应用程序将在2024年1月4日自动升级到上面列出的新模型。在未来几周内，通过在API调用中指定以下模型名称，新模型也将可供早期测试：ada-002，babbage-002，curie-002，davinci-002。&lt;/p&gt;

&lt;p&gt;使用其他旧完成模型（如text-davinci-003）的开发者将需要在2024年1月4日之前手动升级他们的集成，通过在他们的API请求的“模型”参数中指定gpt-3.5-turbo-instruct。gpt-3.5-turbo-instruct是一个InstructGPT风格的模型，训练方式类似于text-davinci-003。这个新模型是Completions API中的替换模型，并将在未来几周内可供早期测试。&lt;/p&gt;

&lt;p&gt;希望在2024年1月4日之后继续使用他们的微调模型的开发者将需要在新的基础GPT-3模型（ada-002，babbage-002，curie-002，davinci-002）或新模型（gpt-3.5-turbo，gpt-4）上微调替代模型。一旦今年晚些时候提供了这个功能，我们将给予以前微调过旧模型的用户GPT-3.5 Turbo和GPT-4微调的优先访问权。我们承认，迁移离基于您自己数据的微调模型是具有挑战性的。我们将为以前微调过模型的用户提供支持，使这个过渡尽可能顺利。
在未来几周内，我们将联系最近使用过这些旧模型的开发者，并在新的完成模型准备好进行早期测试后提供更多信息。&lt;/p&gt;

&lt;h2 id=&quot;废弃旧的嵌入模型&quot;&gt;废弃旧的嵌入模型&lt;/h2&gt;

&lt;p&gt;旧的嵌入模型的用户（例如，text-search-davinci-doc-001）将需要在2024年1月4日之前迁移到text-embedding-ada-002。我们在2022年12月发布了text-embedding-ada-002，并发现它比以前的模型更有能力和成本效益。今天，text-embedding-ada-002占据了所有嵌入API使用的99.9%。&lt;/p&gt;

&lt;p&gt;我们认识到这对使用那些旧模型的开发者来说是一个重大的改变。我们并不轻易做出淘汰这些模型的决定。我们将承担用户使用这些新模型重新嵌入内容的财务成本。我们将在未来几天内与受影响的用户取得联系。&lt;/p&gt;

&lt;p&gt;旧模型&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;code-search-ada-code-001
code-search-ada-text-001	
code-search-babbage-code-001	
code-search-babbage-text-001	
text-search-ada-doc-001	
text-search-ada-query-001	
text-search-babbage-doc-001	
text-search-babbage-query-001	
text-search-curie-doc-001	
text-search-curie-query-001	
text-search-davinci-doc-001	
text-search-davinci-query-001	
text-similarity-ada-001	
text-similarity-babbage-001	
text-similarity-curie-001	
text-similarity-davinci-001
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;新模型
text-embedding-ada-002&lt;/p&gt;

&lt;h2 id=&quot;废弃edits-api&quot;&gt;废弃Edits API&lt;/h2&gt;
&lt;p&gt;Edits API及其关联模型的用户（例如，text-davinci-edit-001或code-davinci-edit-001）将需要在2024年1月4日之前迁移到GPT-3.5 Turbo。Edits API beta是一个早期的探索性API，旨在使开发者能够根据指令返回提示的编辑版本。我们在开发gpt-3.5-turbo和Chat Completions API时考虑了来自Edits API的反馈，现在可以用于同样的目的。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;System
Apply the change requested by the user to the code.

User
def fibonacci(num):
    if num &amp;lt;= 1:
        return num
    else:
        return fibonacci(num-1) + fibonacci(num-2)
print(fibonacci(10))

User
Rename the function to fib.

Assistant
def fib(num):
    if num &amp;lt;= 1:
        return num
    else:
        return fib(num-1) + fib(num-2)
print(fib(10))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Sun, 09 Jul 2023 00:00:00 -0500</pubDate>
        <link>https://magicwind.top/gpt/2023/07/09/gpt-4-general-availablity/</link>
        <guid isPermaLink="true">https://magicwind.top/gpt/2023/07/09/gpt-4-general-availablity/</guid>
        
        
        <category>gpt</category>
        
      </item>
    
  </channel>
</rss>
